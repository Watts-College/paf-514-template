library( quanteda.textmodels )
install.packages("quanteda.textmodels")
install.packages("quanteda.textstats")
install.packages("quanteda.textplots")
library( dplyr )
library( pander )
library( quanteda )
library( quanteda.textmodels )
library( quanteda.textstats )
library( quanteda.textplots )
URL <- "https://github.com/DS4PS/cpp-527-spr-2020/blob/master/labs/data/IRS-1023-EZ-MISSIONS.rds?raw=true"
dat <- readRDS(gzcon(url( URL )))
head( dat[ c("orgname","codedef01","mission") ] ) %>% pander()
dat$mission <- tolower( dat$mission )
dat.sample <- dat[ sample( 1:50000, size=1000 ) , ]
corp <- corpus( dat.sample,  text_field="mission" )
summary(corp)[1:10,] 
summary(corp)[1:10,] %>% knitr::kable()
summary(corp)[1:10,] %>% knitr::kable(align="c")
corp <- corpus_trim( corp, what="sentences", min_ntoken=3 )
tokens <- tokens( corp, what="word", remove_punct=TRUE )
head( tokens )
ngram2 <- tokens_ngrams( tokens, n=2 ) %>% dfm()
ngram2 %>% textstat_frequency( n=10 )
tokens %>% dfm( stem=F ) %>% topfeatures( )
tokens %>%
  dfm() %>% 
  dfm_wordstem() %>% 
  topfeatures()
tokens %>% 
  dfm() %>% 
  topfeatures()
tokens <- tokens_remove( tokens, c( stopwords("english"), "nbsp" ), padding=F )
tokens %>% 
  dfm() %>% 
  topfeatures()
tokens %>%
  dfm() %>% 
  dfm_wordstem() %>% 
  topfeatures()
head( dat )
head( dat$mission )
dat$mission <- 
  dat$mission %>%
  tolower()
dat.sample <- 
  dat %>% 
  sample_n( 1000 )
corp <- 
  dat.sample %>% 
  corpus( text_field="mission" )
class( dat )
class( corp )
(corp)[1:10,] %>% 
  summary %>% 
  knitr::kable(align="c")
corp <- corpus_trim( corp, what="sentences", min_ntoken=3 )
tokens <- tokens( corp, what="word", remove_punct=TRUE )
head( tokens )
mode( corpus )
mode( corp )
mode( tokens )
class( tokens )
tokens %>% 
  dfm() %>% 
  topfeatures()
tokens <- tokens_remove( tokens, c( stopwords("english"), "nbsp" ), padding=F )
tokens %>% 
  dfm() %>% 
  topfeatures()
my_dictionary <- dictionary( list( five01_c_3= c("501 c 3","section 501 c 3") ,
                             united_states = c("united states"),
                             high_school=c("high school"),
                             non_profit=c("non-profit", "non profit", "nonprofit"),
                             stem=c("science technology engineering math", 
                                    "science technology engineering mathematics" ),
                             los_angeles=c("los angeles"),
                             ny_state=c("new york state"),
                             ny=c("new york")
                           ))
tokens <- tokens_compound( tokens, pattern=my_dictionary )
ngram2 <- tokens_ngrams( tokens, n=2 ) %>% dfm()
ngram2 %>% textstat_frequency( n=10 )
ngram2 %>% textstat_frequency( n=100 )
ngram3 <- tokens_ngrams( tokens, n=3 ) %>% dfm()
ngram3 %>% textstat_frequency( n=10 )
ngram3 <- tokens_ngrams( tokens, n=5 ) %>% dfm()
ngram3 %>% textstat_frequency( n=10 )
ngram2 <- tokens_ngrams( tokens, n=2 )
ngram2
tokens_ngrams( tokens, n=2 ) %>% dfm()
ngram2 <- tokens_ngrams( tokens, n=2 ) %>% dfm()
ngram2 %>% textstat_frequency( n=10 )
tokens %>% dfm() %>% topfeatures( )
tokens %>% dfm( stem=T ) %>% topfeatures()
tokens %>% 
  dfm() %>% 
  topfeatures()
tokens %>%
  dfm() %>% 
  dfm_wordstem() %>% 
  topfeatures()
